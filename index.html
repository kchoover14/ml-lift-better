<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.9.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>How You Lift Matters: Wearable Sensors Can Detect Exercise Form Errors with 99% Accuracy</title>
<style>
/* Default styles provided by pandoc.
** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
*/
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="ml-lift-better_files/libs/clipboard/clipboard.min.js"></script>
<script src="ml-lift-better_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="ml-lift-better_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="ml-lift-better_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="ml-lift-better_files/libs/quarto-html/popper.min.js"></script>
<script src="ml-lift-better_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="ml-lift-better_files/libs/quarto-html/anchor.min.js"></script>
<link href="ml-lift-better_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="ml-lift-better_files/libs/quarto-html/quarto-syntax-highlighting-076ecbd647e1f0418c5051713cd9b730.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="ml-lift-better_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="ml-lift-better_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="ml-lift-better_files/libs/bootstrap/bootstrap-fdc35ccebf6ef883c9ad23e25989f106.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="blues quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#executive-summary" id="toc-executive-summary" class="nav-link active" data-scroll-target="#executive-summary">Executive Summary</a></li>
  <li><a href="#research-question" id="toc-research-question" class="nav-link" data-scroll-target="#research-question">Research Question</a></li>
  <li><a href="#research-answers" id="toc-research-answers" class="nav-link" data-scroll-target="#research-answers">Research Answers</a>
  <ul class="collapse">
  <li><a href="#decision-tree-chance-level-performance" id="toc-decision-tree-chance-level-performance" class="nav-link" data-scroll-target="#decision-tree-chance-level-performance">Decision Tree: Chance-Level Performance</a></li>
  <li><a href="#resampling-recovers-performance" id="toc-resampling-recovers-performance" class="nav-link" data-scroll-target="#resampling-recovers-performance">Resampling Recovers Performance</a></li>
  <li><a href="#gradient-boosting-comparable-to-bagging" id="toc-gradient-boosting-comparable-to-bagging" class="nav-link" data-scroll-target="#gradient-boosting-comparable-to-bagging">Gradient Boosting: Comparable to Bagging</a></li>
  <li><a href="#random-forest-best-model" id="toc-random-forest-best-model" class="nav-link" data-scroll-target="#random-forest-best-model">Random Forest: Best Model</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  <li><a href="#study-design" id="toc-study-design" class="nav-link" data-scroll-target="#study-design">Study Design</a></li>
  <li><a href="#project-resources" id="toc-project-resources" class="nav-link" data-scroll-target="#project-resources">Project Resources</a></li>
  <li><a href="#tools-technologies" id="toc-tools-technologies" class="nav-link" data-scroll-target="#tools-technologies">Tools &amp; Technologies</a></li>
  <li><a href="#expertise" id="toc-expertise" class="nav-link" data-scroll-target="#expertise">Expertise</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">How You Lift Matters: Wearable Sensors Can Detect Exercise Form Errors with 99% Accuracy</h1>
  <div class="quarto-categories">
    <div class="quarto-category">machine learning</div>
    <div class="quarto-category">random forest</div>
    <div class="quarto-category">gradient boosting</div>
    <div class="quarto-category">decision tree</div>
    <div class="quarto-category">classification</div>
    <div class="quarto-category">lifting form</div>
  </div>
  </div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 2021</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="executive-summary" class="level2">
<h2 class="anchored" data-anchor-id="executive-summary">Executive Summary</h2>
<p><strong>Problem:</strong> Fitness tracking technology typically measures whether people exercise but not how well they move. Poor exercise form is a leading cause of injury, yet wearable sensors are rarely used to distinguish correct technique from specific, identifiable mistakes in real time.</p>
<p><strong>Approach:</strong> Accelerometer data from sensors strapped to participants’ belts, forearms, arms, and dumbbells were used to classify bicep curl form across five categories: one correct technique (Class A) and four defined errors (Classes B–E), including elbow flaring, incomplete range of motion, and excessive hip involvement. Four machine learning algorithms were compared – a decision tree, a bagged decision tree, a gradient boosted random forest, and a random forest – to identify which model best separates form classes and which sensor locations contribute most to accurate classification.</p>
<p><strong>Insights:</strong> The random forest model achieved 99.4% accuracy with an out-of-sample error of just 0.6%, substantially outperforming the decision tree (49.7%) and demonstrating the power of ensemble methods for high-dimensional sensor classification. Accuracy peaked at 27 of 52 predictors rather than the full set, suggesting the model is over-parameterized and that a leaner deployment model is achievable with domain-informed feature selection.</p>
<p><strong>Significance:</strong> As wearable fitness technology becomes more accessible, the ability to classify movement quality – not just movement quantity – opens the door to real-time coaching and injury prevention at scale. This project shows that a single well-tuned ensemble model can reliably distinguish between correct form and specific movement errors, which has direct application in consumer fitness devices and physical rehabilitation monitoring.</p>
<p><strong>Key Findings</strong></p>
<ul>
<li>The random forest model achieved 99.4% accuracy (95% CI: 99.2–99.5%) with a Kappa of 0.992, correctly classifying all five form categories.</li>
<li>The decision tree performed at chance (49.7% accuracy) and failed to predict Class D (half-range lifting) entirely – a failure resolved completely by the random forest.</li>
<li>Resampling methods consistently outperformed the single decision tree: the bagged tree reached 95.8% accuracy and the gradient boosted forest reached 96.3%.</li>
<li>Model accuracy peaked at 27 predictors and declined at the full 52, indicating potential collinearity and a clear opportunity for feature reduction.</li>
<li>Sensor location and predictor importance varied across models, suggesting that a minimal sensor deployment (fewer than four body locations) may be sufficient for accurate classification.</li>
</ul>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p><strong>Applied Findings</strong></p>
<ul>
<li>Ensemble methods – particularly random forests – are substantially more effective than single decision trees for classifying multi-class movement data from wearable sensors.</li>
<li>A production-ready wearable form classifier could be built on approximately half the current predictor set; domain expertise in exercise physiology should guide final feature selection.</li>
<li>Collinearity analysis is a recommended next step before any model deployment to avoid falsely inflated accuracy estimates.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="research-question" class="level2">
<h2 class="anchored" data-anchor-id="research-question">Research Question</h2>
<p>Can wearable accelerometer sensors reliably distinguish between correct exercise form and specific, defined technique errors during bicep curls – and if so, which sensor locations and model types provide the most accurate classification?</p>
</section>
<section id="research-answers" class="level2">
<h2 class="anchored" data-anchor-id="research-answers">Research Answers</h2>
<p>The core question was whether machine learning models could differentiate not just whether someone exercised, but how well they moved. The answer depends entirely on the model chosen: a single decision tree cannot solve this problem, but ensemble methods can.</p>
<section id="decision-tree-chance-level-performance" class="level3">
<h3 class="anchored" data-anchor-id="decision-tree-chance-level-performance">Decision Tree: Chance-Level Performance</h3>
<p>The rpart decision tree achieved 49.7% accuracy – statistically indistinguishable from random guessing. Its most critical failure was a complete inability to predict Class D (half-range lifting), where sensitivity was undefined (NA) and prevalence was recorded as zero. Classes B and C also showed weak performance. This model is not fit for purpose.</p>
<p><strong>Table 1. Confusion Matrix – Decision Tree (rpart)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>A</strong></td>
<td>2032</td>
<td>41</td>
<td>154</td>
<td>0</td>
<td>5</td>
</tr>
<tr class="even">
<td><strong>B</strong></td>
<td>624</td>
<td>525</td>
<td>369</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td><strong>C</strong></td>
<td>646</td>
<td>33</td>
<td>689</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td><strong>D</strong></td>
<td>577</td>
<td>244</td>
<td>465</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td><strong>E</strong></td>
<td>211</td>
<td>191</td>
<td>383</td>
<td>0</td>
<td>657</td>
</tr>
</tbody>
</table>
<p><strong>Table 2. Performance Statistics by Class – Decision Tree (rpart)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Statistic</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sensitivity</td>
<td>0.497</td>
<td>0.508</td>
<td>0.335</td>
<td>NA</td>
<td>0.992</td>
</tr>
<tr class="even">
<td>Specificity</td>
<td>0.947</td>
<td>0.854</td>
<td>0.883</td>
<td>0.836</td>
<td>0.891</td>
</tr>
<tr class="odd">
<td>Pos Pred Value</td>
<td>0.910</td>
<td>0.346</td>
<td>0.504</td>
<td>NA</td>
<td>0.456</td>
</tr>
<tr class="even">
<td>Neg Pred Value</td>
<td>0.633</td>
<td>0.920</td>
<td>0.788</td>
<td>NA</td>
<td>0.999</td>
</tr>
<tr class="odd">
<td>Prevalence</td>
<td>0.521</td>
<td>0.132</td>
<td>0.263</td>
<td>0.000</td>
<td>0.084</td>
</tr>
<tr class="even">
<td>Detection Rate</td>
<td>0.259</td>
<td>0.067</td>
<td>0.088</td>
<td>0.000</td>
<td>0.084</td>
</tr>
<tr class="odd">
<td>Detection Prevalence</td>
<td>0.284</td>
<td>0.194</td>
<td>0.174</td>
<td>0.164</td>
<td>0.184</td>
</tr>
<tr class="even">
<td>Balanced Accuracy</td>
<td>0.722</td>
<td>0.681</td>
<td>0.609</td>
<td>NA</td>
<td>0.942</td>
</tr>
</tbody>
</table>
<p><strong>Interpretation:</strong> The decision tree’s failure to detect Class D at all reflects a fundamental limitation of single-tree classifiers on high-dimensional, correlated sensor data. The model lacks the variance-reduction mechanisms needed to separate visually similar movement patterns.</p>
</section>
<section id="resampling-recovers-performance" class="level3">
<h3 class="anchored" data-anchor-id="resampling-recovers-performance">Resampling Recovers Performance</h3>
<p>Resampling methods substantially recovered classification performance. The bagged tree – which averages multiple models produced by resampling – reached 95.8% accuracy (95% CI: 95.4–96.3%, Kappa: 0.947) and successfully predicted all five classes, with sensitivity ranging from 0.934 (Class C) to 0.982 (Class E).</p>
<p><strong>Table 3. Confusion Matrix – Decision Tree (bag)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>A</strong></td>
<td>2180</td>
<td>28</td>
<td>10</td>
<td>9</td>
<td>5</td>
</tr>
<tr class="even">
<td><strong>B</strong></td>
<td>33</td>
<td>1429</td>
<td>36</td>
<td>11</td>
<td>9</td>
</tr>
<tr class="odd">
<td><strong>C</strong></td>
<td>2</td>
<td>47</td>
<td>1294</td>
<td>24</td>
<td>1</td>
</tr>
<tr class="even">
<td><strong>D</strong></td>
<td>6</td>
<td>5</td>
<td>33</td>
<td>1231</td>
<td>11</td>
</tr>
<tr class="odd">
<td><strong>E</strong></td>
<td>5</td>
<td>18</td>
<td>13</td>
<td>22</td>
<td>1384</td>
</tr>
</tbody>
</table>
<p><strong>Table 4. Performance Statistics by Class – Decision Tree (bag)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Statistic</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sensitivity</td>
<td>0.979</td>
<td>0.936</td>
<td>0.934</td>
<td>0.949</td>
<td>0.982</td>
</tr>
<tr class="even">
<td>Specificity</td>
<td>0.991</td>
<td>0.986</td>
<td>0.989</td>
<td>0.992</td>
<td>0.991</td>
</tr>
<tr class="odd">
<td>Pos Pred Value</td>
<td>0.977</td>
<td>0.941</td>
<td>0.946</td>
<td>0.957</td>
<td>0.960</td>
</tr>
<tr class="even">
<td>Neg Pred Value</td>
<td>0.992</td>
<td>0.985</td>
<td>0.986</td>
<td>0.990</td>
<td>0.996</td>
</tr>
<tr class="odd">
<td>Prevalence</td>
<td>0.284</td>
<td>0.195</td>
<td>0.177</td>
<td>0.165</td>
<td>0.180</td>
</tr>
<tr class="even">
<td>Detection Rate</td>
<td>0.278</td>
<td>0.182</td>
<td>0.165</td>
<td>0.157</td>
<td>0.176</td>
</tr>
<tr class="odd">
<td>Detection Prevalence</td>
<td>0.284</td>
<td>0.193</td>
<td>0.174</td>
<td>0.164</td>
<td>0.184</td>
</tr>
<tr class="even">
<td>Balanced Accuracy</td>
<td>0.985</td>
<td>0.961</td>
<td>0.961</td>
<td>0.970</td>
<td>0.986</td>
</tr>
</tbody>
</table>
<p><strong>Figure 3. Variable Importance – Decision Tree (bag)</strong></p>
<p><img src="bag-varImportance.png" class="img-fluid"></p>
<p><strong>Interpretation:</strong> The jump from chance-level accuracy (rpart) to 95.8% (bag) using the same underlying data illustrates how variance reduction through resampling addresses the core weakness of single decision trees on noisy sensor data.</p>
</section>
<section id="gradient-boosting-comparable-to-bagging" class="level3">
<h3 class="anchored" data-anchor-id="gradient-boosting-comparable-to-bagging">Gradient Boosting: Comparable to Bagging</h3>
<p>The gradient boosted random forest reached 96.3% accuracy (95% CI: 95.9–96.7%, Kappa: 0.953), marginally above the bagged tree. Sensitivity across all five classes ranged from 0.934 (Class B) to 0.993 (Class E), with no class falling below the threshold for practical utility.</p>
<p><strong>Table 5. Confusion Matrix – Random Forest (gbm)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>A</strong></td>
<td>2187</td>
<td>34</td>
<td>6</td>
<td>5</td>
<td>0</td>
</tr>
<tr class="even">
<td><strong>B</strong></td>
<td>49</td>
<td>1435</td>
<td>28</td>
<td>2</td>
<td>4</td>
</tr>
<tr class="odd">
<td><strong>C</strong></td>
<td>0</td>
<td>44</td>
<td>1299</td>
<td>22</td>
<td>3</td>
</tr>
<tr class="even">
<td><strong>D</strong></td>
<td>0</td>
<td>10</td>
<td>28</td>
<td>1245</td>
<td>3</td>
</tr>
<tr class="odd">
<td><strong>E</strong></td>
<td>2</td>
<td>14</td>
<td>15</td>
<td>20</td>
<td>1391</td>
</tr>
</tbody>
</table>
<p><strong>Table 6. Performance Statistics by Class – Random Forest (gbm)</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Statistic</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sensitivity</td>
<td>0.977</td>
<td>0.934</td>
<td>0.944</td>
<td>0.962</td>
<td>0.993</td>
</tr>
<tr class="even">
<td>Specificity</td>
<td>0.992</td>
<td>0.987</td>
<td>0.989</td>
<td>0.994</td>
<td>0.992</td>
</tr>
<tr class="odd">
<td>Pos Pred Value</td>
<td>0.980</td>
<td>0.945</td>
<td>0.950</td>
<td>0.968</td>
<td>0.965</td>
</tr>
<tr class="even">
<td>Neg Pred Value</td>
<td>0.991</td>
<td>0.984</td>
<td>0.988</td>
<td>0.993</td>
<td>0.998</td>
</tr>
<tr class="odd">
<td>Prevalence</td>
<td>0.285</td>
<td>0.196</td>
<td>0.175</td>
<td>0.165</td>
<td>0.179</td>
</tr>
<tr class="even">
<td>Detection Rate</td>
<td>0.279</td>
<td>0.183</td>
<td>0.166</td>
<td>0.159</td>
<td>0.177</td>
</tr>
<tr class="odd">
<td>Detection Prevalence</td>
<td>0.284</td>
<td>0.193</td>
<td>0.174</td>
<td>0.164</td>
<td>0.184</td>
</tr>
<tr class="even">
<td>Balanced Accuracy</td>
<td>0.985</td>
<td>0.960</td>
<td>0.967</td>
<td>0.978</td>
<td>0.992</td>
</tr>
</tbody>
</table>
<p><strong>Figure 4. Variable Importance – Random Forest (gbm)</strong></p>
<p><img src="gbm-varImportance.png" class="img-fluid"></p>
<p><strong>Interpretation:</strong> Gradient boosting and bagging reached nearly identical accuracy, suggesting that for this dataset the primary performance driver is ensemble resampling itself rather than the specific weighting strategy used.</p>
</section>
<section id="random-forest-best-model" class="level3">
<h3 class="anchored" data-anchor-id="random-forest-best-model">Random Forest: Best Model</h3>
<p>The random forest model achieved the highest overall accuracy at 99.4% (95% CI: 99.2–99.5%, Kappa: 0.992), with sensitivity above 0.989 for all five classes. It is the recommended model for this classification task.</p>
<p><strong>Table 7. Confusion Matrix – Random Forest</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th></th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>A</strong></td>
<td>2228</td>
<td>3</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td><strong>B</strong></td>
<td>13</td>
<td>1503</td>
<td>2</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<td><strong>C</strong></td>
<td>0</td>
<td>4</td>
<td>1357</td>
<td>7</td>
<td>0</td>
</tr>
<tr class="even">
<td><strong>D</strong></td>
<td>0</td>
<td>1</td>
<td>9</td>
<td>1276</td>
<td>0</td>
</tr>
<tr class="odd">
<td><strong>E</strong></td>
<td>0</td>
<td>0</td>
<td>3</td>
<td>7</td>
<td>1432</td>
</tr>
</tbody>
</table>
<p><strong>Table 8. Performance Statistics by Class – Random Forest</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Statistic</th>
<th>A</th>
<th>B</th>
<th>C</th>
<th>D</th>
<th>E</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sensitivity</td>
<td>0.994</td>
<td>0.995</td>
<td>0.989</td>
<td>0.989</td>
<td>1.000</td>
</tr>
<tr class="even">
<td>Specificity</td>
<td>0.999</td>
<td>0.998</td>
<td>0.998</td>
<td>0.998</td>
<td>0.998</td>
</tr>
<tr class="odd">
<td>Pos Pred Value</td>
<td>0.998</td>
<td>0.990</td>
<td>0.992</td>
<td>0.992</td>
<td>0.993</td>
</tr>
<tr class="even">
<td>Neg Pred Value</td>
<td>0.998</td>
<td>0.999</td>
<td>0.998</td>
<td>0.998</td>
<td>1.000</td>
</tr>
<tr class="odd">
<td>Prevalence</td>
<td>0.286</td>
<td>0.193</td>
<td>0.175</td>
<td>0.164</td>
<td>0.183</td>
</tr>
<tr class="even">
<td>Detection Rate</td>
<td>0.284</td>
<td>0.192</td>
<td>0.173</td>
<td>0.163</td>
<td>0.183</td>
</tr>
<tr class="odd">
<td>Detection Prevalence</td>
<td>0.284</td>
<td>0.193</td>
<td>0.174</td>
<td>0.164</td>
<td>0.184</td>
</tr>
<tr class="even">
<td>Balanced Accuracy</td>
<td>0.997</td>
<td>0.996</td>
<td>0.994</td>
<td>0.994</td>
<td>0.999</td>
</tr>
</tbody>
</table>
<p><strong>Figure 1. Random Forest Model Error by Number of Trees</strong></p>
<p><img src="rf-errorVtrees.png" class="img-fluid"></p>
<p><strong>Interpretation:</strong> Model error declines rapidly through the first 100 trees and stabilizes around 200, indicating convergence. Each line represents one of the five form classes (A–E). The plateau after ~200 trees confirms that additional trees do not improve performance and that a smaller forest could be used in a leaner deployment.</p>
<p><strong>Figure 2. Variable Importance – Random Forest</strong></p>
<p><img src="rf-varImportance.png" class="img-fluid"></p>
<p><strong>Interpretation:</strong> Variable importance identifies the sensor readings most responsible for accurate classification. Accuracy peaks at 27 of 52 predictors – the model does not benefit from the full predictor set. Collinear predictors may be inflating apparent accuracy; weighting or removing correlated variables is a recommended next step. Domain expertise in exercise physiology would be valuable in determining which of the top predictors reflect biomechanically meaningful signals.</p>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<ul>
<li><strong>Feature reduction:</strong> Conduct a collinearity analysis on the 52 predictors. Collinear variables can inflate apparent accuracy; weighting or removing them would produce a leaner, more honest model.</li>
<li><strong>Sensor minimization:</strong> Examine whether the top-ranked predictors cluster on specific body locations. If so, a simpler single-sensor or dual-sensor deployment may be sufficient for reliable classification.</li>
<li><strong>Domain validation:</strong> Collaborate with an exercise physiologist to evaluate whether the most important predictors correspond to biomechanically meaningful movement signals or are sensor artifacts.</li>
<li><strong>Deployment testing:</strong> Evaluate whether accuracy holds under real-world conditions – varied populations, fatigue, different dumbbell weights – before considering integration into consumer fitness technology.</li>
</ul>
</section>
<section id="study-design" class="level2">
<h2 class="anchored" data-anchor-id="study-design">Study Design</h2>
<p><strong>Data Source:</strong> The Weight Lifting Exercise Dataset was collected by <a href="http://groupware.les.inf.puc-rio.br/har">Velloso et al.&nbsp;(2013)</a> as part of the Human Activity Recognition project at the Pontifical Catholic University of Rio de Janeiro. Sensors were strapped to participants’ belts, forearms, upper arms, and dumbbells during supervised bicep curl sessions. Participants performed the exercise in one correct form and four defined incorrect forms under expert supervision. Training and test datasets are publicly available.</p>
<p><strong>Data Handling:</strong> Variables unrelated to exercise performance (participant ID, timestamps, window metadata) were removed from both training and test sets. Variables with high proportions of missing values were excluded, leaving 52 predictors from the original feature set. The outcome variable (classe) identifies form category: A (correct), B (elbows forward), C (halfway up), D (halfway down), E (hips forward).</p>
<p><strong>Analytical Approach:</strong></p>
<ol type="1">
<li>Data partitioned 60/40 into training and test sets using stratified random sampling on classe.</li>
<li>Four models trained using the caret package with 5-fold cross-validation via trainControl: decision tree (rpart), bagged decision tree (bag), gradient boosted random forest (gbm), and random forest (rf).</li>
<li>Each model evaluated on the held-out test set using confusionMatrix: overall accuracy, Kappa, and per-class sensitivity and specificity.</li>
<li>Variable importance extracted for all models to identify top predictors.</li>
<li>Random forest accuracy evaluated across predictor counts (2 to 52) to identify the optimal predictor subset.</li>
</ol>
</section>
<section id="project-resources" class="level2">
<h2 class="anchored" data-anchor-id="project-resources">Project Resources</h2>
<p><strong>Repository:</strong> <a href="https://github.com/kchoover14/ml-lift-better">github.com/kchoover14/ml-lift-better</a></p>
<p><strong>Data:</strong> Training and test datasets from the <a href="http://groupware.les.inf.puc-rio.br/har">Weight Lifting Exercise Dataset</a> (Velloso et al., 2013), publicly available. Not included in this repository.</p>
<p><strong>Code:</strong></p>
<ul>
<li><code>ml-lift-better.R</code> – data cleaning, partitioning, model training, and figure export for all four classifiers</li>
</ul>
<p><strong>Project Artifacts:</strong></p>
<ul>
<li>Figures (n=4): variable importance plots for all models; random forest error by tree count</li>
</ul>
<p><strong>Environment:</strong></p>
<ul>
<li><code>renv.lock</code> and <code>renv/</code> – restore with <code>renv::restore()</code></li>
</ul>
<p><strong>License:</strong></p>
<ul>
<li>Code and scripts © Kara C. Hoover, licensed under the <a href="LICENSE">MIT License</a>.</li>
<li>Data, figures, and written content © Kara C. Hoover, licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>.</li>
</ul>
</section>
<section id="tools-technologies" class="level2">
<h2 class="anchored" data-anchor-id="tools-technologies">Tools &amp; Technologies</h2>
<p><strong>Languages:</strong> R</p>
<p><strong>Tools:</strong> caret | renv</p>
<p><strong>Packages:</strong> dplyr | ggplot2 | GGally | caret | rattle | party | rpart.plot | randomForest | gbm</p>
</section>
<section id="expertise" class="level2">
<h2 class="anchored" data-anchor-id="expertise">Expertise</h2>
<p><strong>Domain Expertise:</strong> machine learning | classification | ensemble methods | wearable sensor data | model evaluation</p>
<p><strong>Transferable Expertise:</strong> Demonstrates ability to select and compare competing model types, diagnose failure modes in underperforming algorithms, and translate classification results into actionable deployment recommendations for applied technology contexts.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>